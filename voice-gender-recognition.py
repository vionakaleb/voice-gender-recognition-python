# -*- coding: utf-8 -*-
"""35_Viona_Mid_GenderRecognitionTrain.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E_GeLJl7G4M7XRuueWWR6PBPu3PFDFrh
"""

pip install SpeechRecognition

!pip install pyaudio

!pip install pydub

# Use audio file wav. Label each recording as "male" or "female".
# Name format: male_testN.wav

import os
import numpy as np
import pydub
import matplotlib.pyplot as plt
# import pyaudio

# To train the gender recognition model
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.svm import LinearSVC
import speech_recognition as sr

# Comparing male & female audio samples
male1 = pydub.AudioSegment.from_file('male_test3.wav')
female1 = pydub.AudioSegment.from_file('female_test3.wav')

arrayMale1 = np.array(male1.get_array_of_samples())
arrayFemale1 = np.array(female1.get_array_of_samples())

# Male & Female audio plot.
print("Male & Female audio plot.")
print("Length:", len(arrayMale1), len(arrayFemale1))

plt.figure(figsize=[20,6])

plt.subplot(2,1,1)
plt.plot(arrayMale1) 

plt.subplot(2,1,2)
plt.plot(arrayFemale1)

# Load the sample audio files (male_testN.wav)
arrAudio = []
arrGender = []
for filename in os.listdir():
    if filename.endswith(".wav"):
        gender = filename.split("_")[0]
        audio = sr.AudioFile(os.path.join("data", filename))
        arrAudio.append(audio)
        arrGender.append(gender)

print("Samples:", arrGender)

# Convert the audio files to feature vectors
vectorizer = CountVectorizer(analyzer="word")
arrAudio = vectorizer.fit_transform(arrGender)

# Split the data into training and testing sets
arrAudio_train, arrAudio_test, arrGender_train, arrGender_test = train_test_split(arrAudio, arrGender, test_size=0.2)

# Trains a support vector machine (SVM) classifier to recognize the gender from audio
clf = LinearSVC()
clf.fit(arrAudio_train, arrGender_train)

# Evaluates the accuracy of the classifier model using a test set
accuracy = clf.score(arrAudio_test, arrGender_test)
print("Accuracy:", accuracy)

# Record a new audio file
# r = sr.Recognizer()
# with sr.Microphone() as source:
#     print("Say something!")
#     audio = r.listen(source)

# Load test audio (test.wav)
arrAudio_test = []
arrGender_test = []
for filename in os.listdir():
    if filename.startswith("test"):
        gender = filename.split("_")[0]
        audio = sr.AudioFile(os.path.join("data", filename))
        arrAudio_test.append(audio)
        arrGender_test.append(gender)

# audio_test = pydub.AudioSegment.from_file('test.wav')
# arrAudio_test = np.array(audio_test.get_array_of_samples())

# arrAudio_new = vectorizer.transform([audio])
arrAudio_new = vectorizer.fit_transform(arrGender_test)

print(arrAudio_new)

# Use the classifier to predict the gender
gender = clf.predict(arrAudio_new)
print("Predicted voice:", gender)